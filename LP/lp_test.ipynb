{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test linear programming\n",
    "- simplex method\n",
    "- [realpython linear programming](https://realpython.com/linear-programming-python/)\n",
    "- AMP_02_solving_linear_programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function linprog in module scipy.optimize._linprog:\n",
      "\n",
      "linprog(c, A_ub=None, b_ub=None, A_eq=None, b_eq=None, bounds=None, method='interior-point', callback=None, options=None, x0=None)\n",
      "    Linear programming: minimize a linear objective function subject to linear\n",
      "    equality and inequality constraints.\n",
      "    \n",
      "    Linear programming solves problems of the following form:\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "        \\min_x \\ & c^T x \\\\\n",
      "        \\mbox{such that} \\ & A_{ub} x \\leq b_{ub},\\\\\n",
      "        & A_{eq} x = b_{eq},\\\\\n",
      "        & l \\leq x \\leq u ,\n",
      "    \n",
      "    where :math:`x` is a vector of decision variables; :math:`c`,\n",
      "    :math:`b_{ub}`, :math:`b_{eq}`, :math:`l`, and :math:`u` are vectors; and\n",
      "    :math:`A_{ub}` and :math:`A_{eq}` are matrices.\n",
      "    \n",
      "    Informally, that's:\n",
      "    \n",
      "    minimize::\n",
      "    \n",
      "        c @ x\n",
      "    \n",
      "    such that::\n",
      "    \n",
      "        A_ub @ x <= b_ub\n",
      "        A_eq @ x == b_eq\n",
      "        lb <= x <= ub\n",
      "    \n",
      "    Note that by default ``lb = 0`` and ``ub = None`` unless specified with\n",
      "    ``bounds``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    c : 1D array\n",
      "        The coefficients of the linear objective function to be minimized.\n",
      "    A_ub : 2D array, optional\n",
      "        The inequality constraint matrix. Each row of ``A_ub`` specifies the\n",
      "        coefficients of a linear inequality constraint on ``x``.\n",
      "    b_ub : 1D array, optional\n",
      "        The inequality constraint vector. Each element represents an\n",
      "        upper bound on the corresponding value of ``A_ub @ x``.\n",
      "    A_eq : 2D array, optional\n",
      "        The equality constraint matrix. Each row of ``A_eq`` specifies the\n",
      "        coefficients of a linear equality constraint on ``x``.\n",
      "    b_eq : 1D array, optional\n",
      "        The equality constraint vector. Each element of ``A_eq @ x`` must equal\n",
      "        the corresponding element of ``b_eq``.\n",
      "    bounds : sequence, optional\n",
      "        A sequence of ``(min, max)`` pairs for each element in ``x``, defining\n",
      "        the minimum and maximum values of that decision variable. Use ``None`` to\n",
      "        indicate that there is no bound. By default, bounds are ``(0, None)``\n",
      "        (all decision variables are non-negative).\n",
      "        If a single tuple ``(min, max)`` is provided, then ``min`` and\n",
      "        ``max`` will serve as bounds for all decision variables.\n",
      "    method : {'interior-point', 'revised simplex', 'simplex'}, optional\n",
      "        The algorithm used to solve the standard form problem.\n",
      "        :ref:`'interior-point' <optimize.linprog-interior-point>` (default),\n",
      "        :ref:`'revised simplex' <optimize.linprog-revised_simplex>`, and\n",
      "        :ref:`'simplex' <optimize.linprog-simplex>` (legacy)\n",
      "        are supported.\n",
      "    callback : callable, optional\n",
      "        If a callback function is provided, it will be called at least once per\n",
      "        iteration of the algorithm. The callback function must accept a single\n",
      "        `scipy.optimize.OptimizeResult` consisting of the following fields:\n",
      "    \n",
      "            x : 1D array\n",
      "                The current solution vector.\n",
      "            fun : float\n",
      "                The current value of the objective function ``c @ x``.\n",
      "            success : bool\n",
      "                ``True`` when the algorithm has completed successfully.\n",
      "            slack : 1D array\n",
      "                The (nominally positive) values of the slack,\n",
      "                ``b_ub - A_ub @ x``.\n",
      "            con : 1D array\n",
      "                The (nominally zero) residuals of the equality constraints,\n",
      "                ``b_eq - A_eq @ x``.\n",
      "            phase : int\n",
      "                The phase of the algorithm being executed.\n",
      "            status : int\n",
      "                An integer representing the status of the algorithm.\n",
      "    \n",
      "                ``0`` : Optimization proceeding nominally.\n",
      "    \n",
      "                ``1`` : Iteration limit reached.\n",
      "    \n",
      "                ``2`` : Problem appears to be infeasible.\n",
      "    \n",
      "                ``3`` : Problem appears to be unbounded.\n",
      "    \n",
      "                ``4`` : Numerical difficulties encountered.\n",
      "    \n",
      "            nit : int\n",
      "                The current iteration number.\n",
      "            message : str\n",
      "                A string descriptor of the algorithm status.\n",
      "    \n",
      "    options : dict, optional\n",
      "        A dictionary of solver options. All methods accept the following\n",
      "        options:\n",
      "    \n",
      "            maxiter : int\n",
      "                Maximum number of iterations to perform.\n",
      "                Default: see method-specific documentation.\n",
      "            disp : bool\n",
      "                Set to ``True`` to print convergence messages.\n",
      "                Default: ``False``.\n",
      "            autoscale : bool\n",
      "                Set to ``True`` to automatically perform equilibration.\n",
      "                Consider using this option if the numerical values in the\n",
      "                constraints are separated by several orders of magnitude.\n",
      "                Default: ``False``.\n",
      "            presolve : bool\n",
      "                Set to ``False`` to disable automatic presolve.\n",
      "                Default: ``True``.\n",
      "            rr : bool\n",
      "                Set to ``False`` to disable automatic redundancy removal.\n",
      "                Default: ``True``.\n",
      "    \n",
      "        For method-specific options, see\n",
      "        :func:`show_options('linprog') <show_options>`.\n",
      "    \n",
      "    x0 : 1D array, optional\n",
      "        Guess values of the decision variables, which will be refined by\n",
      "        the optimization algorithm. This argument is currently used only by the\n",
      "        'revised simplex' method, and can only be used if `x0` represents a\n",
      "        basic feasible solution.\n",
      "    \n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : OptimizeResult\n",
      "        A :class:`scipy.optimize.OptimizeResult` consisting of the fields:\n",
      "    \n",
      "            x : 1D array\n",
      "                The values of the decision variables that minimizes the\n",
      "                objective function while satisfying the constraints.\n",
      "            fun : float\n",
      "                The optimal value of the objective function ``c @ x``.\n",
      "            slack : 1D array\n",
      "                The (nominally positive) values of the slack variables,\n",
      "                ``b_ub - A_ub @ x``.\n",
      "            con : 1D array\n",
      "                The (nominally zero) residuals of the equality constraints,\n",
      "                ``b_eq - A_eq @ x``.\n",
      "            success : bool\n",
      "                ``True`` when the algorithm succeeds in finding an optimal\n",
      "                solution.\n",
      "            status : int\n",
      "                An integer representing the exit status of the algorithm.\n",
      "    \n",
      "                ``0`` : Optimization terminated successfully.\n",
      "    \n",
      "                ``1`` : Iteration limit reached.\n",
      "    \n",
      "                ``2`` : Problem appears to be infeasible.\n",
      "    \n",
      "                ``3`` : Problem appears to be unbounded.\n",
      "    \n",
      "                ``4`` : Numerical difficulties encountered.\n",
      "    \n",
      "            nit : int\n",
      "                The total number of iterations performed in all phases.\n",
      "            message : str\n",
      "                A string descriptor of the exit status of the algorithm.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    show_options : Additional options accepted by the solvers.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This section describes the available solvers that can be selected by the\n",
      "    'method' parameter.\n",
      "    \n",
      "    :ref:`'interior-point' <optimize.linprog-interior-point>` is the default\n",
      "    as it is typically the fastest and most robust method.\n",
      "    :ref:`'revised simplex' <optimize.linprog-revised_simplex>` is more\n",
      "    accurate for the problems it solves.\n",
      "    :ref:`'simplex' <optimize.linprog-simplex>` is the legacy method and is\n",
      "    included for backwards compatibility and educational purposes.\n",
      "    \n",
      "    Method *interior-point* uses the primal-dual path following algorithm\n",
      "    as outlined in [4]_. This algorithm supports sparse constraint matrices and\n",
      "    is typically faster than the simplex methods, especially for large, sparse\n",
      "    problems. Note, however, that the solution returned may be slightly less\n",
      "    accurate than those of the simplex methods and will not, in general,\n",
      "    correspond with a vertex of the polytope defined by the constraints.\n",
      "    \n",
      "    .. versionadded:: 1.0.0\n",
      "    \n",
      "    Method *revised simplex* uses the revised simplex method as described in\n",
      "    [9]_, except that a factorization [11]_ of the basis matrix, rather than\n",
      "    its inverse, is efficiently maintained and used to solve the linear systems\n",
      "    at each iteration of the algorithm.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Method *simplex* uses a traditional, full-tableau implementation of\n",
      "    Dantzig's simplex algorithm [1]_, [2]_ (*not* the\n",
      "    Nelder-Mead simplex). This algorithm is included for backwards\n",
      "    compatibility and educational purposes.\n",
      "    \n",
      "    .. versionadded:: 0.15.0\n",
      "    \n",
      "    Before applying any method, a presolve procedure based on [8]_ attempts\n",
      "    to identify trivial infeasibilities, trivial unboundedness, and potential\n",
      "    problem simplifications. Specifically, it checks for:\n",
      "    \n",
      "    - rows of zeros in ``A_eq`` or ``A_ub``, representing trivial constraints;\n",
      "    - columns of zeros in ``A_eq`` `and` ``A_ub``, representing unconstrained\n",
      "      variables;\n",
      "    - column singletons in ``A_eq``, representing fixed variables; and\n",
      "    - column singletons in ``A_ub``, representing simple bounds.\n",
      "    \n",
      "    If presolve reveals that the problem is unbounded (e.g. an unconstrained\n",
      "    and unbounded variable has negative cost) or infeasible (e.g. a row of\n",
      "    zeros in ``A_eq`` corresponds with a nonzero in ``b_eq``), the solver\n",
      "    terminates with the appropriate status code. Note that presolve terminates\n",
      "    as soon as any sign of unboundedness is detected; consequently, a problem\n",
      "    may be reported as unbounded when in reality the problem is infeasible\n",
      "    (but infeasibility has not been detected yet). Therefore, if it is\n",
      "    important to know whether the problem is actually infeasible, solve the\n",
      "    problem again with option ``presolve=False``.\n",
      "    \n",
      "    If neither infeasibility nor unboundedness are detected in a single pass\n",
      "    of the presolve, bounds are tightened where possible and fixed\n",
      "    variables are removed from the problem. Then, linearly dependent rows\n",
      "    of the ``A_eq`` matrix are removed, (unless they represent an\n",
      "    infeasibility) to avoid numerical difficulties in the primary solve\n",
      "    routine. Note that rows that are nearly linearly dependent (within a\n",
      "    prescribed tolerance) may also be removed, which can change the optimal\n",
      "    solution in rare cases. If this is a concern, eliminate redundancy from\n",
      "    your problem formulation and run with option ``rr=False`` or\n",
      "    ``presolve=False``.\n",
      "    \n",
      "    Several potential improvements can be made here: additional presolve\n",
      "    checks outlined in [8]_ should be implemented, the presolve routine should\n",
      "    be run multiple times (until no further simplifications can be made), and\n",
      "    more of the efficiency improvements from [5]_ should be implemented in the\n",
      "    redundancy removal routines.\n",
      "    \n",
      "    After presolve, the problem is transformed to standard form by converting\n",
      "    the (tightened) simple bounds to upper bound constraints, introducing\n",
      "    non-negative slack variables for inequality constraints, and expressing\n",
      "    unbounded variables as the difference between two non-negative variables.\n",
      "    Optionally, the problem is automatically scaled via equilibration [12]_.\n",
      "    The selected algorithm solves the standard form problem, and a\n",
      "    postprocessing routine converts the result to a solution to the original\n",
      "    problem.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Dantzig, George B., Linear programming and extensions. Rand\n",
      "           Corporation Research Study Princeton Univ. Press, Princeton, NJ,\n",
      "           1963\n",
      "    .. [2] Hillier, S.H. and Lieberman, G.J. (1995), \"Introduction to\n",
      "           Mathematical Programming\", McGraw-Hill, Chapter 4.\n",
      "    .. [3] Bland, Robert G. New finite pivoting rules for the simplex method.\n",
      "           Mathematics of Operations Research (2), 1977: pp. 103-107.\n",
      "    .. [4] Andersen, Erling D., and Knud D. Andersen. \"The MOSEK interior point\n",
      "           optimizer for linear programming: an implementation of the\n",
      "           homogeneous algorithm.\" High performance optimization. Springer US,\n",
      "           2000. 197-232.\n",
      "    .. [5] Andersen, Erling D. \"Finding all linearly dependent rows in\n",
      "           large-scale linear programming.\" Optimization Methods and Software\n",
      "           6.3 (1995): 219-227.\n",
      "    .. [6] Freund, Robert M. \"Primal-Dual Interior-Point Methods for Linear\n",
      "           Programming based on Newton's Method.\" Unpublished Course Notes,\n",
      "           March 2004. Available 2/25/2017 at\n",
      "           https://ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/lecture-notes/lec14_int_pt_mthd.pdf\n",
      "    .. [7] Fourer, Robert. \"Solving Linear Programs by Interior-Point Methods.\"\n",
      "           Unpublished Course Notes, August 26, 2005. Available 2/25/2017 at\n",
      "           http://www.4er.org/CourseNotes/Book%20B/B-III.pdf\n",
      "    .. [8] Andersen, Erling D., and Knud D. Andersen. \"Presolving in linear\n",
      "           programming.\" Mathematical Programming 71.2 (1995): 221-245.\n",
      "    .. [9] Bertsimas, Dimitris, and J. Tsitsiklis. \"Introduction to linear\n",
      "           programming.\" Athena Scientific 1 (1997): 997.\n",
      "    .. [10] Andersen, Erling D., et al. Implementation of interior point\n",
      "            methods for large scale linear programming. HEC/Universite de\n",
      "            Geneve, 1996.\n",
      "    .. [11] Bartels, Richard H. \"A stabilization of the simplex method.\"\n",
      "            Journal in  Numerische Mathematik 16.5 (1971): 414-434.\n",
      "    .. [12] Tomlin, J. A. \"On scaling linear programming problems.\"\n",
      "            Mathematical Programming Study 4 (1975): 146-166.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Consider the following problem:\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "        \\min_{x_0, x_1} \\ -x_0 + 4x_1 & \\\\\n",
      "        \\mbox{such that} \\ -3x_0 + x_1 & \\leq 6,\\\\\n",
      "        -x_0 - 2x_1 & \\geq -4,\\\\\n",
      "        x_1 & \\geq -3.\n",
      "    \n",
      "    The problem is not presented in the form accepted by `linprog`. This is\n",
      "    easily remedied by converting the \"greater than\" inequality\n",
      "    constraint to a \"less than\" inequality constraint by\n",
      "    multiplying both sides by a factor of :math:`-1`. Note also that the last\n",
      "    constraint is really the simple bound :math:`-3 \\leq x_1 \\leq \\infty`.\n",
      "    Finally, since there are no bounds on :math:`x_0`, we must explicitly\n",
      "    specify the bounds :math:`-\\infty \\leq x_0 \\leq \\infty`, as the\n",
      "    default is for variables to be non-negative. After collecting coeffecients\n",
      "    into arrays and tuples, the input for this problem is:\n",
      "    \n",
      "    >>> c = [-1, 4]\n",
      "    >>> A = [[-3, 1], [1, 2]]\n",
      "    >>> b = [6, 4]\n",
      "    >>> x0_bounds = (None, None)\n",
      "    >>> x1_bounds = (-3, None)\n",
      "    >>> from scipy.optimize import linprog\n",
      "    >>> res = linprog(c, A_ub=A, b_ub=b, bounds=[x0_bounds, x1_bounds])\n",
      "    \n",
      "    Note that the default method for `linprog` is 'interior-point', which is\n",
      "    approximate by nature.\n",
      "    \n",
      "    >>> print(res)\n",
      "         con: array([], dtype=float64)\n",
      "         fun: -21.99999984082494 # may vary\n",
      "     message: 'Optimization terminated successfully.'\n",
      "         nit: 6 # may vary\n",
      "       slack: array([3.89999997e+01, 8.46872439e-08] # may vary\n",
      "      status: 0\n",
      "     success: True\n",
      "           x: array([ 9.99999989, -2.99999999]) # may vary\n",
      "    \n",
      "    If you need greater accuracy, try 'revised simplex'.\n",
      "    \n",
      "    >>> res = linprog(c, A_ub=A, b_ub=b, bounds=[x0_bounds, x1_bounds], method='revised simplex')\n",
      "    >>> print(res)\n",
      "         con: array([], dtype=float64)\n",
      "         fun: -22.0 # may vary\n",
      "     message: 'Optimization terminated successfully.'\n",
      "         nit: 1 # may vary\n",
      "       slack: array([39.,  0.]) # may vary\n",
      "      status: 0\n",
      "     success: True\n",
      "           x: array([10., -3.]) # may vary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# linprog doc\n",
    "help(linprog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: realpython\n",
    "- we aim to have negative result since it's reverse of objective function due to program limitation that it could only minimize not maximize\n",
    "- [image](C:\\Users\\apansukij\\Projects\\MyLearning\\LP\\image\\example1.png)\n",
    "\n",
    "minimize::\n",
    "    \n",
    "        c @ x\n",
    "    \n",
    "    such that::\n",
    "    \n",
    "        A_ub @ x <= b_ub\n",
    "        A_eq @ x == b_eq\n",
    "        lb <= x <= ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameter fill\n",
    "- linprog() solves only minimization (not mazimization) problems and doesn't allow inequality constraints with ge (greater or equal to >=).\n",
    "- A is a matrix\n",
    "\"\"\"\n",
    "c = [-1, -2]\n",
    "\n",
    "# equal\n",
    "A_eq = [[-1, 5]]\n",
    "b_eq = [15]\n",
    "\n",
    "# le (less than on equal to)\n",
    "A_ub = [[2, 1], [-4, 5], [1, -2]]\n",
    "b_ub = [20, 10, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1],\n",
       "       [-4,  5],\n",
       "       [ 1, -2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(A_ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     con: array([0.])\n",
       "     fun: -16.818181818181817\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 5\n",
       "   slack: array([ 0.        , 18.18181818,  3.36363636])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([7.72727273, 4.54545455])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = linprog(c = c, A_ub = A_ub, b_ub = b_ub, A_eq = A_eq, b_eq = b_eq\n",
    "        , bounds = [(0, float(\"inf\")), (0, float(\"inf\"))]\n",
    "        , method = 'simplex')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     con: array([0.])\n",
       "     fun: -16.818181818181817\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 3\n",
       "   slack: array([ 0.        , 18.18181818,  3.36363636])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([7.72727273, 4.54545455])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = linprog(c = c, A_ub = A_ub, b_ub = b_ub, A_eq = A_eq, b_eq = b_eq\n",
    "        , bounds = [(0, float(\"inf\")), (0, float(\"inf\"))]\n",
    "        , method = 'revised simplex')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apansukij\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     con: array([5.11171763e-08])\n",
       "     fun: -16.81818175142891\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 4\n",
       "   slack: array([8.29900628e-08, 1.81818181e+01, 3.36363636e+00])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([7.72727269, 4.54545453])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = linprog(c = c, A_ub = A_ub, b_ub = b_ub, A_eq = A_eq, b_eq = b_eq\n",
    "        , bounds = [(0, float(\"inf\")), (0, float(\"inf\"))]\n",
    "        , method = 'interior-point')\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "- Preview simplex method in AMP_02 page 38\n",
    "\n",
    "Problem statement::\n",
    "    \n",
    "    Maximize z = 0x1 + 0x2 -3x3 -x4 + 20\n",
    "\n",
    "    s.t.\n",
    "    x1 + 0x2 - 3x3 + 3x4 = 6\n",
    "    0x1 + x2 - 8x3 + 4x4 = 4\n",
    "    xj >= 0 where j between 1 and 4\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn maximize problem into minimize problem\n",
    "c = [0, 0, 3, 4]\n",
    "\n",
    "A_eq = [[1, 0, -3, 3], [0, 1, -8, 4]]\n",
    "b_eq = [6, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     con: array([0., 0.])\n",
       "     fun: 0.0\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 4\n",
       "   slack: array([], dtype=float64)\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([6., 4., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linprog(c = c, A_eq = A_eq, b_eq = b_eq\n",
    "    , bounds = [(0, float(\"inf\")), (0, float(\"inf\")), (0, float(\"inf\")), (0, float(\"inf\"))]\n",
    "    , method = 'simplex'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05fd015fde469287f816b397886c05d451759986eacea9f691480d314851b517"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
